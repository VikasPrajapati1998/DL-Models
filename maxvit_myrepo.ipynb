{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8072671,"sourceType":"datasetVersion","datasetId":4763520}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install onnxruntime-gpu\n!pip install onnxconverter-common\n!pip install apache-tvm\n!pip install torch\n!pip install numpy\n!pip install onnxruntime\n!pip install onnx\n!pip install onnxsim\n!pip install timm\n!pip install tqdm\n!pip install torchvision\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T05:21:31.335320Z","iopub.execute_input":"2024-04-10T05:21:31.336183Z","iopub.status.idle":"2024-04-10T05:24:01.740131Z","shell.execute_reply.started":"2024-04-10T05:21:31.336144Z","shell.execute_reply":"2024-04-10T05:24:01.738883Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting onnxruntime-gpu\n  Downloading onnxruntime_gpu-1.17.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nCollecting coloredlogs (from onnxruntime-gpu)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.12)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime-gpu) (3.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\nDownloading onnxruntime_gpu-1.17.1-cp310-cp310-manylinux_2_28_x86_64.whl (192.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.17.1\nCollecting onnxconverter-common\n  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from onnxconverter-common) (1.26.4)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from onnxconverter-common) (1.16.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxconverter-common) (21.3)\nCollecting protobuf==3.20.2 (from onnxconverter-common)\n  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxconverter-common) (3.1.1)\nDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, onnxconverter-common\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.2 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\ntensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\ntensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed onnxconverter-common-1.14.0 protobuf-3.20.2\nCollecting apache-tvm\n  Downloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\nRequirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (23.2.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (2.2.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (5.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (1.26.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (5.9.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (1.11.4)\nCollecting synr==0.6.0 (from apache-tvm)\n  Downloading synr-0.6.0-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: tornado in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (6.3.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from apache-tvm) (4.9.0)\nDownloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading synr-0.6.0-py3-none-any.whl (18 kB)\nInstalling collected packages: synr, apache-tvm\nSuccessfully installed apache-tvm-0.11.1 synr-0.6.0\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nCollecting onnxruntime\n  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.12)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\nDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: onnxruntime\nSuccessfully installed onnxruntime-1.17.1\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (1.16.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from onnx) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx) (3.20.2)\nCollecting onnxsim\n  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from onnxsim) (1.16.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from onnxsim) (13.7.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from onnx->onnxsim) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->onnxsim) (3.20.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->onnxsim) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->onnxsim) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\nDownloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: onnxsim\nSuccessfully installed onnxsim-0.4.36\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.1.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# import libraries\nimport os\nimport torch\nimport json\nimport time\nfrom tqdm.auto import tqdm\nimport timm\nimport numpy as np\nimport onnxruntime as ort\nfrom onnxruntime import quantization\nfrom onnxconverter_common import float16\nfrom onnxsim import simplify \nimport onnx\nimport tvm\nfrom tvm import relay\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:24:13.027884Z","iopub.execute_input":"2024-04-10T05:24:13.028248Z","iopub.status.idle":"2024-04-10T05:24:20.647316Z","shell.execute_reply.started":"2024-04-10T05:24:13.028216Z","shell.execute_reply":"2024-04-10T05:24:20.646277Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device = \", device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:24:23.705426Z","iopub.execute_input":"2024-04-10T05:24:23.705932Z","iopub.status.idle":"2024-04-10T05:24:23.732068Z","shell.execute_reply.started":"2024-04-10T05:24:23.705902Z","shell.execute_reply":"2024-04-10T05:24:23.730431Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"device =  cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess(model):\n    data_config = timm.data.resolve_model_data_config(model)\n    transforms = timm.data.create_transform(**data_config, is_training = False)\n    print(transforms)\n    \n    val_dataset = timm.data.ImageDataset('/kaggle/input/imagenet/imagenet-mini', transform = transforms)\n    val_loader = timm.data.create_loader(val_dataset, (1, 3, 224, 224), 1)\n    \n    val_dataset_sub = torch.utils.data.Subset(val_dataset, list(range(1000)))\n    val_loader_sub = timm.data.create_loader(val_dataset_sub, (1, 3, 224, 224), 1)\n    \n    return val_loader, val_loader_sub\n\nprint(\"Preprocess Done ...!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:24:24.618576Z","iopub.execute_input":"2024-04-10T05:24:24.618923Z","iopub.status.idle":"2024-04-10T05:24:24.626294Z","shell.execute_reply.started":"2024-04-10T05:24:24.618895Z","shell.execute_reply":"2024-04-10T05:24:24.625405Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Preprocess Done ...!\n","output_type":"stream"}]},{"cell_type":"code","source":"class OnnxStaticQuantization:\n    def __init__(self) -> None:\n        self.enum_data = None\n        self.calibration_technique = {\n            \"MinMax\": ort.quantization.calibrate.CalibrationMethod.MinMax,\n            \"Entropy\": ort.quantization.calibrate.CalibrationMethod.Entropy,\n            \"Percentile\": ort.quantization.calibrate.CalibrationMethod.Percentile,\n            \"Distribution\": ort.quantization.calibrate.CalibrationMethod.Distribution\n        }\n\n    def get_next(self, EP_list = ['CPUExecutionProvider']):\n        if self.enum_data is None:\n            session = ort.InferenceSession(self.fp32_onnx_path, providers = EP_list)\n            input_name = session.get_inputs()[0].name\n            calib_list = []\n            count = 0\n            for nhwc_data, _ in self.calibration_loader:\n                nhwc_data=nhwc_data.cpu()\n                calib_list.append({input_name: nhwc_data.numpy()}) \n                if self.sample == count: break\n                count = count + 1\n            self.enum_data = iter(calib_list)\n        return next(self.enum_data, None)\n    \n    def quantization(self, fp32_onnx_path, future_onnx_path, calib_method, calibration_loader, sample = 100):\n        self.sample = sample\n        self.calibration_loader = calibration_loader \n        _ = ort.quantization.quantize_static(\n                model_input = fp32_onnx_path,\n                model_output = future_onnx_path,\n                calibrate_method = self.calibration_technique[calib_method],\n                activation_type=ort.quantization.QuantType.QInt8,\n                weight_type=ort.quantization.QuantType.QInt8,\n                per_channel = True, \n                reduce_range = True,\n                calibration_data_reader = self\n            )\n        return self\n\n\nprint(\"Quantization Done ...!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:24:25.306466Z","iopub.execute_input":"2024-04-10T05:24:25.307381Z","iopub.status.idle":"2024-04-10T05:24:25.319281Z","shell.execute_reply.started":"2024-04-10T05:24:25.307347Z","shell.execute_reply":"2024-04-10T05:24:25.318242Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Quantization Done ...!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Quantization Investigation\ndef quant_investigation(quant_model_name):\n    _model = onnx.load(quant_model_name + \".onnx\")\n    initializers = _model.graph.initializer\n\n    for node_i in _model.graph.node:\n        if node_i.output and \"QuantizeLinear\" not in node_i.output[0] and \"DequantizeLinear\" not in node_i.name:\n            for node_j in _model.graph.node:\n                if node_j.input and node_i.output[0] == node_j.input[0] and \"QuantizeLinear\" not in node_j.output[0]:\n                    print(node_i.name)\n\nprint(\"Quantization Investigation Done ...!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:24:26.072704Z","iopub.execute_input":"2024-04-10T05:24:26.073051Z","iopub.status.idle":"2024-04-10T05:24:26.079823Z","shell.execute_reply.started":"2024-04-10T05:24:26.073024Z","shell.execute_reply":"2024-04-10T05:24:26.079007Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Quantization Investigation Done ...!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Validation \ndef validate(model, val_loader, model_name, ONNX = False, quant = \"\", sample_size = 100, quant_invest = False, TVM = False):\n    correct = 0\n    total = 0\n    elapsed_time = 0\n    top5_correct = 0\n    \n    if ONNX:    # 1\n        if not TVM:    # 2  \n            if quant == \"fp16\":    # 3\n                model = onnx.load(model_name + \".onnx\")\n                model_fp16 = float16.convert_float_to_float16(model)\n                onnx.save(model_fp16,model_name + quant + \".onnx\")\n                \n            elif quant == \"int8\":    # 3\n                ort.quantization.shape_inference.quant_pre_process(model_name + \".onnx\", \"preprocess.onnx\")\n                module = OnnxStaticQuantization()\n                module.fp32_onnx_path = \"preprocess.onnx\"\n                \n                module.quantization(\n                    fp32_onnx_path = \"preprocess.onnx\",\n                    future_onnx_path = model_name + quant + \".onnx\",\n#                     calib_method = \"MinMax\",\n#                     calib_method = \"Entropy\",\n                    calib_method = \"Percentile\",\n#                     calib_method = \"Distribution\",\n                    calibration_loader = val_loader,\n                    sample = sample_size)\n                \n            elif quant == \"fp32\" :  # 3\n                dummy_input = torch.randn(1, 3, 224, 224).to(device)\n                torch.onnx.export(model, dummy_input, model_name + quant + \".onnx\", export_params = True, opset_version = 14, do_constant_folding = True)\n                \n            else:    # 3\n                dummy_input = torch.randn(1, 3, 224, 224).to(device)\n                torch.onnx.export(model, dummy_input, model_name + \".onnx\", export_params = True, opset_version = 14, do_constant_folding = True)\n                \n                \n        else:    # 2\n            onnx_model = onnx.load(model_name + quant + \".onnx\")\n            shape_dict = {\"input.1\": (1, 3, 224, 224)}\n            mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n            target = \"llvm -mcpu=core-avx2\"\n            with tvm.transform.PassContext(opt_level = 2):\n                executor = relay.build_module.create_executor(\"graph\", mod, tvm.cpu(0), target, params).evaluate()\n        \n        # -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n        \n        sess = ort.InferenceSession(model_name + quant + \".onnx\", providers = ['CPUExecutionProvider'])\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader)):\n            if quant == \"fp16\":\n                inputs = inputs.half()\n            inputs = inputs.cpu().numpy()\n            \n            if TVM:\n                if quant == \"fp16\":\n                    inputs = tvm.nd.array(inputs.astype(\"float16\"))\n                    start_time = time.time()    \n                    outputs = [executor(inputs).numpy()]\n                    end_time = time.time()\n                else:\n                    inputs = tvm.nd.array(inputs.astype(\"float32\"))\n                    start_time = time.time()    \n                    outputs = [executor(inputs).numpy()]\n                    end_time = time.time()\n                \n            else:\n                start_time = time.time()    \n                outputs = sess.run(None, {sess.get_inputs()[0].name: inputs})\n                end_time = time.time()\n            \n            elapsed_time += end_time - start_time\n\n            predicted_labels = np.argmax(outputs[0], axis=1)\n\n            correct += (predicted_labels == labels.cpu().numpy()).sum()\n            total += labels.size(0)\n\n            top5_predicted = np.argsort(outputs[0], axis=1)[:, -5:]  \n            top5_correct += np.sum(np.equal(top5_predicted, np.expand_dims(labels.cpu().numpy(), axis=1)))\n    \n    \n    elif ONNX == False and quant_invest == True and quant != \"\":    # 1\n        if quant == \"fp16\" :\n            print(\"fp16 quantization investigation : \")\n            quant_investigation(model_name + quant)\n            print()\n        elif quant == \"int8\" :\n            print(\"int8 quantization investigation : \")\n            quant_investigation(model_name + quant)\n            print()\n        elif quant == \"fp32\" : \n            print(\"fp32 quantization investigation : \")\n            quant_investigation(model_name + quant)\n            print()\n        else :\n            print(\"Error : quant is empty.\")\n        return\n    \n    \n    else:  # 1\n        print(\"Default Model Accuracy Calculate : \")\n        model = model.eval()\n        with torch.inference_mode():\n            for batch_idx, (images, labels) in enumerate(tqdm(val_loader)):\n                images, labels = images.to(device), labels.to(device)\n                \n                start_time = time.time()\n                outputs = model(images)\n                end_time = time.time()\n                elapsed_time += end_time - start_time\n                \n                _, predicted = torch.max(outputs.softmax(dim = 1) * 100, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                _, top5_predicted = torch.topk(outputs.softmax(dim = 1) * 100, k = 5)\n                top5_correct += sum(labels[i].item() in top5_predicted[i] for i in range(len(labels)))\n    \n    # ==================================================================================================================================================================================\n    \n    # Calculate accuracy\n    if total != 0 :\n        single_inference_runtime = elapsed_time / total\n        top1Accuracy = correct / total\n        top5Accuracy = top5_correct / total\n\n        print('Single Inference Runtime: {:.4f} seconds\\nTop 1 Accuracy : {:.2f}%\\nTop 5 Accuracy : {:.2f}%\\n'.format(single_inference_runtime, 100 * top1Accuracy, 100 * top5Accuracy))\n\n\nprint(\"Validation Done ...!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:33:46.069672Z","iopub.execute_input":"2024-04-10T05:33:46.070082Z","iopub.status.idle":"2024-04-10T05:33:46.097317Z","shell.execute_reply.started":"2024-04-10T05:33:46.070054Z","shell.execute_reply":"2024-04-10T05:33:46.096294Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Validation Done ...!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Load Model**","metadata":{}},{"cell_type":"code","source":"# model load\nmodel = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\ntorch.save(model.state_dict(), 'vit_base_patch16_224.pth')\nprint(\"Model Saved ...!\")\n\nval_loader, val_loader_sub = preprocess(model)\nprint(\"Data Preprocessing Done.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:24:29.123739Z","iopub.execute_input":"2024-04-10T05:24:29.124580Z","iopub.status.idle":"2024-04-10T05:24:51.597128Z","shell.execute_reply.started":"2024-04-10T05:24:29.124546Z","shell.execute_reply":"2024-04-10T05:24:51.596143Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e66c284ee4d4c18a5ad204e1bf0a0cc"}},"metadata":{}},{"name":"stdout","text":"Model Saved ...!\nCompose(\n    Resize(size=248, interpolation=bicubic, max_size=None, antialias=warn)\n    CenterCrop(size=(224, 224))\n    ToTensor()\n    Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n)\nData Preprocessing Done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Baseline Setup**","metadata":{}},{"cell_type":"code","source":"# Baseline Setup : Pytorch Model\nvalidate(model, val_loader_sub, 'vit_base_patch16_224')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:25:14.847521Z","iopub.execute_input":"2024-04-10T05:25:14.847963Z","iopub.status.idle":"2024-04-10T05:25:26.600389Z","shell.execute_reply.started":"2024-04-10T05:25:14.847918Z","shell.execute_reply":"2024-04-10T05:25:26.599449Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Default Model Accuracy Calculate : \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ebff63b844b41e1906ffa9bd225244a"}},"metadata":{}},{"name":"stdout","text":"Single Inference Runtime: 0.0053 seconds\nTop 1 Accuracy : 94.90%\nTop 5 Accuracy : 99.70%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Onnx Export**","metadata":{}},{"cell_type":"code","source":"# Onnx Export : ONNX FP32\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:25:28.085647Z","iopub.execute_input":"2024-04-10T05:25:28.086011Z","iopub.status.idle":"2024-04-10T05:28:51.876391Z","shell.execute_reply.started":"2024-04-10T05:25:28.085984Z","shell.execute_reply":"2024-04-10T05:28:51.875381Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/__init__.py:1404: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  assert condition, message\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2c32007f1be49cf910dae488bb6d013"}},"metadata":{}},{"name":"stdout","text":"Single Inference Runtime: 0.1942 seconds\nTop 1 Accuracy : 94.90%\nTop 5 Accuracy : 99.70%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Onnx Export : ONNX FP16\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=True, sample_size=100, quant=\"fp16\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ***Model Quantization int8***","metadata":{}},{"cell_type":"code","source":"# Model Quantization int8 : QDQ Int8\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=True, sample_size=50, quant=\"int8\") \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model QDQ Investigation\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=False, quant=\"int8\", quant_invest=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **TVM**","metadata":{}},{"cell_type":"code","source":"# Model TVM with fp16 : ONNX FP16\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX = True, sample_size = 50, quant = 'fp16', TVM = True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model TVM with quant int8 : QDQ Int8\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=True, sample_size=50, quant='int8', TVM=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model TVM with quant fp32 : ONNX FP32\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=True, sample_size=100, quant=\"fp32\")\nvalidate(model, val_loader_sub, 'vit_base_patch16_224', ONNX=True, sample_size=50, quant='fp32', TVM=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:34:16.341042Z","iopub.execute_input":"2024-04-10T05:34:16.341884Z","iopub.status.idle":"2024-04-10T06:00:23.336685Z","shell.execute_reply.started":"2024-04-10T05:34:16.341853Z","shell.execute_reply":"2024-04-10T06:00:23.335454Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2551bbbe3d8242b390c9cd79cff3c675"}},"metadata":{}},{"name":"stdout","text":"Single Inference Runtime: 1.4753 seconds\nTop 1 Accuracy : 94.90%\nTop 5 Accuracy : 99.70%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}